# syntax=docker/dockerfile:1
ARG IMAGE=nvcr.io/nvidia/tensorflow:22.01-tf2-py3
FROM ${IMAGE}


# Non-GPU-related prerequisites
ARG CMAKE_VER=3.22.2 \
    HADOOP_VER=3.3.1 \
    HIREDIS_VER=1.0.2 \
    PROTOC_VER=3.19.4 \
    RDKAFKA_VER=1.8.2 \
    REDIS_PP_VER=1.3.3 \
    ROCKSDB_VER=6.28.2 \
# NVIDIA/GPU related
    HWLOC_VER=2.4.1 \
    HWLOC_USE_RELEASE=true \
    RELEASE=false \
    NVTAB_VER=vnightly \
    MODELS_VER=vnightly \
    HUGECTR_VER=vnightly \
    HUGECTR_DEV_MODE=false \
# >>>
# Only valid when $HUGECTR_DEV_MODE==false
    _HUGECTR_BRANCH=master \
    _HUGECTR_REPO="github.com/NVIDIA-Merlin/HugeCTR.git" \
    _CI_JOB_TOKEN="" \
# <<<
    DEBIAN_FRONTEND=noninteractive


#  /--------------------------------------------------------------------------\
# <       Non-GPU-related prerequisites                                        >
#  \--------------------------------------------------------------------------/

# Adjust system configuration.
RUN apt-get remove -y --purge cmake -y && \
    apt-get autoremove -y && \
    apt-get update -y && \
    apt-get install -y --no-install-recommends \
        # Required by protocol buffers.
        autoconf automake libtool \
        # Required by Hadoop (for building).
        default-jdk maven \
        libpmem-dev \
        libsasl2-dev libssl-dev \
        libsnappy-dev libzstd-dev zlib1g-dev \
        # Required by Hadoop (for running).
        openssh-server \
        # Required by RocksDB.
        libgflags-dev \
        zlib1g-dev libbz2-dev libsnappy-dev liblz4-dev libzstd-dev \
        # Required by RdKafka.
        zlib1g-dev libzstd-dev \
        libssl-dev libsasl2-dev \
        # Required HugeCTR.
        libaio-dev libtbb-dev \
        clang-format && \
    ssh-keygen -q -t ecdsa -b 521 -N "" <<< "" && \
    cat $HOME/.ssh/id_ecdsa.pub > $HOME/.ssh/authorized_keys

# Build and install "newer" version CMake.
RUN cd /tmp && \
    git clone --branch v${CMAKE_VER} --depth 1 https://github.com/Kitware/CMake.git && \
    cd CMake && \
    ./bootstrap && \
    make -j$(nproc) && \
    make install && \
    cd .. && \
    rm -rf CMake && \
    cmake --version


# Build and install HDFS native client.
RUN cd /tmp && \
    git clone --branch v${PROTOC_VER} --depth 1 https://github.com/protocolbuffers/protobuf.git && \
    cd protobuf && \
    git submodule update --init --recursive && \
    ./autogen.sh && \
    ./configure && \
    make -j$(nproc) && \
    make install && \
    cd .. && \
    rm -rf protobuf && \
    ldconfig && \
    protoc --version

ENV JAVA_HOME=/usr/lib/jvm/default-java \
    HADOOP_HOME=/opt/hadoop

RUN cd /tmp && \
    # >>> Temporary hack if name resolution doesn't work properly again.
    echo '127.0.0.1 repository.apache.org' >> /etc/hosts && \
    echo '127.0.0.1 repository.jboss.org' >> /etc/hosts && \
    # <<<
    git clone --branch rel/release-${HADOOP_VER} --depth 1 https://github.com/apache/hadoop.git && \
    cd hadoop && \
    # This module can currently not be copiled in this configuration due to a version conflict.
    # However, it is not a direct or indirect dependency of the native client.
    sed -i -e 's/<module>hadoop-yarn-applications-catalog-webapp<\/module>//g' hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-catalog/pom.xml && \
    mvn package -Pdist,native -DskipTests -Dtar -Dmaven.javadoc.skip=true \
        -Drequire.snappy -Drequire.zstd -Drequire.openssl -Drequire.pmdk && \
    mkdir ${HADOOP_HOME} && \
    tar xf hadoop-dist/target/hadoop-${HADOOP_VER}.tar.gz --strip-components 1 --directory ${HADOOP_HOME} && \
    chmod -x ${HADOOP_HOME}/bin/*.cmd && \
    chmod -x ${HADOOP_HOME}/sbin/*.cmd && \
    mkdir ${HADOOP_HOME}/logs && \
    sed -i -e 's/^# export JAVA_HOME=$/export JAVA_HOME=\/usr\/lib\/jvm\/default-java/g' ${HADOOP_HOME}/etc/hadoop/hadoop-env.sh && \
    cd .. && \
    rm -rf hadoop && \
    # Add links to make HDFS native client discoverable on usual paths.
    ln -s ${HADOOP_HOME}/include/hdfs.h /usr/local/include/hdfs.h && \
    ln -s ${HADOOP_HOME}/lib/native/libhdfs.so /usr/local/lib/libhdfs.so

ENV PATH=$PATH:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin \
    LD_LIBRARY_PATH=$LD_LIBRARY_PATH:${HADOOP_HOME}/lib/native \
    HDFS_NAMENODE_USER=root \
    HDFS_SECONDARYNAMENODE_USER=root \
    HDFS_DATANODE_USER=root \
    YARN_RESOURCEMANAGER_USER=root \
    YARN_NODEMANAGER_USER=root

COPY default-hadoop-core-site.xml ${HADOOP_HOME}/etc/hadoop/core-site.xml
COPY default-hadoop-hdfs-site.xml ${HADOOP_HOME}/etc/hadoop/hdfs-site.xml

RUN hadoop version
# To start single-node hadoop instance (for development only):
#   hadoop namenode -format
#   service ssh start
#   start-dfs.sh


# Build and install Redis native client.
RUN cd /tmp && \
    git clone --branch v${HIREDIS_VER} --depth 1 https://github.com/redis/hiredis.git && \
    mkdir hiredis/build && \
    cd hiredis/build && \
    cmake .. && \
    make -j$(nproc) && \
    make install && \
    cd ../.. && \
    rm -rf hiredis

RUN cd /tmp && \
    git clone --branch ${REDIS_PP_VER} --depth 1 https://github.com/sewenew/redis-plus-plus.git && \
    mkdir redis-plus-plus/build && \
    cd redis-plus-plus/build && \
    cmake -DREDIS_PLUS_PLUS_CXX_STANDARD=17 .. && \
    make -j$(nproc) && \
    make install && \
    cd ../.. && \
    rm -rf redis-plus-plus


# Build and install RocksDB.
RUN cd /tmp && \
    git clone --branch v${ROCKSDB_VER} --depth 1 https://github.com/facebook/rocksdb.git && \
    cd rocksdb && \
    PORTABLE=1 make -j$(nproc) shared_lib && \
    make install-shared && \
    cd .. && \
    rm -rf rocksdb


# Build and install RdKafka.
RUN cd /tmp && \
    git clone --branch v${RDKAFKA_VER} --depth 1 https://github.com/edenhill/librdkafka.git && \
    cd librdkafka && \
    ./configure --enable-static && \
    make -j$(nproc) && \
    make install && \
    cd .. && \
    rm -rf librdkafka


#  /--------------------------------------------------------------------------\
# <      GPU/NVIDIA-related                                                    >
#  \--------------------------------------------------------------------------/

# Fix environment.
RUN if [[ ! -f /usr/lib/x86_64-linux-gnu/libibverbs.so ]]; then \
        ln -s /usr/lib/x86_64-linux-gnu/libibverbs.so.1 /usr/lib/x86_64-linux-gnu/libibverbs.so; \
    fi && \
    python -m pip cache purge && \
    python -m pip install --upgrade pip && \
    # Required by NVTabular and HugeCTR.
    python -m pip install --upgrade pybind11 && \
    python -c 'import pybind11; print(pybind11.__version__)'

ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64


# Build and install CUDA compatible hwloc. 
RUN cd /opt/hpcx/ompi/include/openmpi/opal/mca/hwloc/hwloc201 && \
    rm -rf hwloc201.h hwloc/include/hwloc.h && \
    cd /tmp && \
    # OS-provided automake will cause issues if not CUDA driver present.  automake for would add a depdendency cause
    # incompatibilities with make and m4. Hence, we don't do that. Fortunately, the preconfigured
    # release package avoids this issue.
    if [[ "${HWLOC_USE_RELEASE}" == "true" ]]; then \
        mkdir hwloc && \
        curl -L https://download.open-mpi.org/release/hwloc/v2.4/hwloc-${HWLOC_VER}.tar.gz | tar -zx --strip-components 1 --directory ./hwloc && \
        cd hwloc; \
    else \
        git clone --branch hwloc-${HWLOC_VER} --depth 1 https://github.com/open-mpi/hwloc.git && \
        cd hwloc && \
        ./autogen.sh; \
    fi && \
    ./configure CPPFLAGS="-I/usr/local/cuda/include -L/usr/local/cuda/lib64" LDFLAGS="-L/usr/local/cuda/lib64" --enable-cuda && \
    make -j$(nproc) && \
    make install && \
    cd .. && \
    rm -rf hwloc && \
    ldconfig
    # Cannot run because libnvidia-ml.so.1 not present without the driver.
    # && \
    # hwloc-info --version


# Build and install NVTabular.
ENV PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION='python'
RUN cd /opt && \
    if [[ "${RELEASE}" != "true" ]] || [[ "${NVTAB_VER}" == "vnightly" ]]; then NVTAB_VER="main"; fi && \
    git clone --branch ${NVTAB_VER} --depth 1 https://github.com/NVIDIA-Merlin/NVTabular.git nvtabular && \
    cd nvtabular && \
    python setup.py develop --no-deps && \
    cd .. && \
    python -c 'import nvtabular; print(nvtabular.__version__)'


# Build and install HugeCTR.
RUN if [[ "$HUGECTR_DEV_MODE" == "false" ]]; then \
        # Pretend having a CUDA driver.
        ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/libcuda.so.1 && \
        cd /tmp && \
        if [[ "${RELEASE}" != "true" ]] || [[ "${HUGECTR_VER}" == "vnightly" ]]; then HUGECTR_VER="master"; fi && \
        git clone --branch ${HUGECTR_VER} --depth 1 https://${_CI_JOB_TOKEN}${_HUGECTR_REPO} hugectr && \
        cd hugectr && \
        git submodule update --init --recursive && \
        mkdir build && \
        cd build && \
        cmake -DCMAKE_BUILD_TYPE=Release -DSM="60;61;70;75;80" -DENABLE_MULTINODES=ON .. && \
        make -j$(nproc) && \
        make install && \
        chmod +x /usr/local/hugectr/bin/* && \
        chmod +x /usr/local/hugectr/lib/*.so && \
        cd ../onnx_converter && \
        python setup.py install && \
        cd ../.. && \
        rm -rf hugectr && \
        python -c 'import hugectr2onnx; print(hugectr2onnx.__version__)' && \
        # Remove temporary links.
        rm /usr/local/cuda/lib64/libcuda.so.1; \
    fi

ENV PATH=$PATH:/usr/local/hugectr/bin \
    LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/hugectr/lib \
    PYTHONPATH=$PYTHONPATH:/usr/local/hugectr/lib


#  /--------------------------------------------------------------------------\
# <      Finalize environment                                                  >
#  \--------------------------------------------------------------------------/


HEALTHCHECK NONE
CMD ["/bin/bash"]
